{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.data.hex_utils import * \n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/geolife_hex_100.pkl\", 'rb') as f: \n",
    "    hdf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'datetime', 'trajectory', 'user', 't_idx', 'timediff',\n",
       "       'x', 'y', 'dist', 'speed', 'q0', 'r0', 'cell0', 'q1', 'r1', 'cell1',\n",
       "       'q2', 'r2', 'cell2', 'q3', 'r3', 'cell3', 'is_workday', 'is_in_time_0',\n",
       "       'is_in_time_1', 'is_in_time_2', 'is_in_time_3', 'time_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [f\"cell{i}\" for i in range(4)] + [\"user\"]:\n",
    "    hdf[col] += 1\n",
    "\n",
    "hdf.to_pickle(\"../data/processed/geolife_hex_100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence, unpack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 8, 8],\n",
       "        [0, 3, 6, 8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create example data\n",
    "lens = [5, 8]\n",
    "x = [torch.randint(1, 10, (lens[0],)), torch.randint(1, 10, (lens[1],))]\n",
    "t = [torch.arange(6, 6 + lens[0]), torch.arange(6, 6 + lens[1])]\n",
    "\n",
    "\n",
    "class HierarchicEncoder(nn.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_hidden,\n",
    "        embedding_dim_loc,\n",
    "        embedding_dim_time,\n",
    "        n_locs,\n",
    "        n_times,\n",
    "        dropout,\n",
    "        n_layers,\n",
    "        timesteps_split,\n",
    "        device,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_locs = n_locs\n",
    "        self.n_times = n_times\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_dim_loc = embedding_dim_loc\n",
    "        self.embedding_dim_time = embedding_dim_time\n",
    "        self.timesteps_split = timesteps_split\n",
    "        self.embedding_dim = embedding_dim_time + embedding_dim_loc\n",
    "\n",
    "        self.short_encoder = nn.LSTM(\n",
    "            self.embedding_dim,\n",
    "            n_hidden,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.long_encoder = nn.LSTM(\n",
    "            self.embedding_dim,\n",
    "            n_hidden,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self\n",
    "        self.loc_embed = nn.Embedding(n_locs + 1, embedding_dim_loc, padding_idx=0)\n",
    "        self.time_embed = nn.Embedding(n_times + 1, embedding_dim_time, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def decode(self, z):\n",
    "\n",
    "\n",
    "\n",
    "    def long_forward(self, input_packed):\n",
    "        out_packed, (h, c) = self.long_encoder(input_packed)\n",
    "        out, lens_long = pad_packed_sequence(out_packed)\n",
    "        return out.gather(1, lens_long)\n",
    "\n",
    "    def short_forward(self, x, t):\n",
    "        lens_short = torch.tensor([len(xi) for xi in x])\n",
    "        x_pad = pad_sequence(x, batch_first=True)\n",
    "        t_pad = pad_sequence(t, batch_first=True)\n",
    "\n",
    "        t_embed = self.time_embed(t_pad)\n",
    "        x_embed = self.loc_embed(x_pad)\n",
    "        xt_embed = torch.cat([x_embed, t_embed], dim=-1)\n",
    "\n",
    "        # Encode trajectory\n",
    "        x_packed = pack_padded_sequence(\n",
    "            xt_embed, lens_short, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        out_packed, (h, c) = self.short_encoder(x_packed)\n",
    "        out, lens_unpacked = pad_packed_sequence(out_packed)\n",
    "        # out.shape = (batch_size, max_len, 2*n_hidden)\n",
    "        idcs_long, lens_long = self.get_idcs_long(t_pad)\n",
    "        input_long_pad = out.gather(1, idcs_long)\n",
    "        input_long_packed = pack_padded_sequence(\n",
    "            input_long_pad, lens_long, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        input_decoder = out.gather(1, lens_unpacked)\n",
    "        return input_long_packed, input_decoder\n",
    "\n",
    "    def get_idcs_long(self, t_pad):\n",
    "        delta_t = t_pad - t_pad[:, 0, None]\n",
    "        idcs = torch.searchsorted(\n",
    "            delta_t, torch.arange(0, 24, 3)[None, :].expand(2, -1)\n",
    "        )\n",
    "        _, max_len = t_pad.shape\n",
    "        # Get place to cut off idcs\n",
    "        lens = (idcs < max_len).sum(-1) + 1\n",
    "        return idcs[:, : lens.max()], lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  3,  8,  8],\n",
       "        [ 0,  6, 12, 16]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.cat([torch.arange(10)[None, :], torch.arange(10)[None, :]])\n",
    "t[1, :] = t[1] * 2\n",
    "idx = torch.tensor([[0, 3, 8, 8], [0, 3, 6, 8]])\n",
    "t.gather(dim=1, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2, 8, 4)\n",
    "t2 = t.clone()\n",
    "t[0, 5:] = 0\n",
    "t[1, 6:] = 0\n",
    "tp = pack_padded_sequence(t, lengths=torch.tensor([5, 6]), batch_first=True, enforce_sorted=False)\n",
    "tp2 = pack_padded_sequence(t2, lengths=torch.tensor([5, 6]), batch_first=True, enforce_sorted=False)\n",
    "torch.allclose(tp.data, tp2.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lbn-trajectory-forecasting-OLKZBoZP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
