% This file was adapted from ICLR2022_conference.tex example provided for the ICLR conference
\documentclass{article} % For LaTeX2e
\usepackage{collas2025_conference,times}
\usepackage{easyReview}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

% Please leave these options as they are
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=red,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=purple,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }




\title{Efficient Online Trajectory User Linking with Multi-Level Spatial Embedding Sharing}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \collasfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Antiquus S.~Hippocampus, Natalia Cerebro  \thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.  Funding acknowledgements go at the end of the paper.} \\
Department of Computer Science\\
Random University\\
Country \\
\texttt{\{hippo,brain\}@cs.random.edu} \\
\And % Use And to have authors side by side
Koala Learnus \& D. Q. ResNet  \\
Department of Computational Neuroscience \\
University of Random City \\
Another Country \\
\texttt{\{koala,net\}@random.rand} \\
\AND % Use AND to have authors block one under the other
Coauthor \\
Affiliation \\
Address \\
\texttt{email}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\collasfinalcopy % Uncomment for camera-ready version, but NOT for submission.

%\preprintcopy % Uncomment for the preprint version, but NOT for submission.

\begin{document}


\maketitle

\begin{abstract}
   Trajectory-User Linking (TUL), which aims to associate unlabeled spatial trajectories to the users that generated them is a common task in transportation and mobility applications. Recent approaches have demonstrated impressive performance when trained on large datasets of historical check-in data in a batch-mode setting. However, this mode of evaluation is not representative for many real-world TUL applications, where data is not available from the start, but is instead generated incrementally over time. 
   - Online Machine Learning is needed, but understudied. 
   - To bridge this gap, we perform a comprehensive evaluation of the most successful TUL techniques in a streaming setting.
   - Streaming setting exacerbates sparsity problem of mobility data, since TUL models must adapt to concept drifts with a limited amount of data to be able to yield accurate results.
   - To mitigate this issue, we propose a novel approach where locations partially share their embeddings with neighboring locations. 
   - By performing this sharing for multiple neighborhood sizes, we incorporate information with varying levels of specificity and pervasiveness with the goal of enabling fast post-concept drift adaptation while maintaining good performance in phases with stationary data.
\end{abstract}

\section{Introduction}



\section{Related Work}

Classical approaches 
-longest common sub-trajectory
-SVM, logistic regression + bag of words

RNN-based approaches
- TULER: lookup embeddings + LSTM/GRU
- TULVAE: combines Variational Autoencoder with LSTM classifier that is additionally trained to minimize the expected reconstruction error when appending its predictions to the latent embeddings of the AE
- DeepTUL: adds a historical attention module to TULER that generates an additional context vector by embedding historical check-ins present in the trajectory to be classified

Transformer-based approaches
- T3S: uses a transformer that encodes the sequence of visited grid cells which is concatenated with an LSTM embedding of the coordinate sequence
- TULHOR: uses a modified BERT model that is first pre-trained on sequences of check-ins and grid cells in between each check-in and subsequently finetuned for TUL
- MainTUL: makes use of a transformer and an RNN, which both receive either a trajectory augmented with historical trajectories of the same user or only the trajectory to be classified itself. The transformer outputs are distilled into the RNN.



\section{Preliminaries}

\section{Approach}

\section{Experiments}

\section{Conclusion}



\bibliography{collas2025_conference}
\bibliographystyle{collas2025_conference}

\appendix
\section{Appendix}
You may include other additional sections here.

\end{document}
