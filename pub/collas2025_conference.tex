% This file was adapted from ICLR2022_conference.tex example provided for the ICLR conference
\documentclass{article} % For LaTeX2e
\usepackage{collas2025_conference,times}
\usepackage{easyReview}
\usepackage{booktabs, multicol, multirow}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

% Please leave these options as they are
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=red,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=purple,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }




\title{Efficient Online Trajectory User Linking with Multi-Level Spatial Embedding Sharing}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \collasfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Antiquus S.~Hippocampus, Natalia Cerebro  \thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.  Funding acknowledgements go at the end of the paper.} \\
Department of Computer Science\\
Random University\\
Country \\
\texttt{\{hippo,brain\}@cs.random.edu} \\
\And % Use And to have authors side by side
Koala Learnus \& D. Q. ResNet  \\
Department of Computational Neuroscience \\
University of Random City \\
Another Country \\
\texttt{\{koala,net\}@random.rand} \\
\AND % Use AND to have authors block one under the other
Coauthor \\
Affiliation \\
Address \\
\texttt{email}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\collasfinalcopy % Uncomment for camera-ready version, but NOT for submission.

%\preprintcopy % Uncomment for the preprint version, but NOT for submission.

\begin{document}


\maketitle

\begin{abstract}
   Trajectory-User Linking (TUL), which aims to associate unlabeled spatial trajectories to the users that generated them is a common task in transportation and mobility applications. Recent approaches have demonstrated impressive performance when trained on large datasets of historical check-in data in a batch-mode setting. However, this mode of evaluation is not representative for many real-world TUL applications, where data is not available from the start, but is instead generated incrementally over time. 
   - Online Machine Learning is needed, but understudied. 
   - To bridge this gap, we perform a comprehensive evaluation of the most successful TUL techniques in a streaming setting.
   - Streaming setting exacerbates sparsity problem of mobility data, since TUL models must adapt to concept drifts with a limited amount of data to be able to yield accurate results.
   - To mitigate this issue, we propose a novel approach where locations partially share their embeddings with neighboring locations. 
   - By performing this sharing for multiple neighborhood sizes, we incorporate information with varying levels of specificity and pervasiveness with the goal of enabling fast post-concept drift adaptation while maintaining good performance in phases with stationary data.
\end{abstract}

\section{Introduction}

- mobility data has become abundant thanks to the proliferation of devices supporting location services 
- this has spawned a variety of machine learning tasks, specifically catered to make use of this type of data
- one such task is Trajectory User Linking (TUL), introduced by \citet{gaoIdentifyingHumanMobility2017}
- originally TUL was proposed with the specific application in  of linking users of location based social networks to unlabeled trajectories \cite{gaoIdentifyingHumanMobility2017}  
- TUL has many more practical applications in areas such as ride-hailing, logistics, or law-enforcement make use 
- Previous works have achieved remarkable results using recurrent neural networks and more recently with transformer-based approaches 
- These works are limited to conventional batch-learning where all training data is available at once. 
- In many real-world applications, data is generated continously in the form of data streams. 
- When establishing a new location-based service i.e. the amount of initial data available for training may be small or zero. 
- Furthermore, real-world data is often affected by shifts in their distributions in the form of concept drift. 
- For mobility data, such shifts may occur due to seasonality, openings or closures of points of interest, changes in user activity 
- Therefore, it can be beneficial to 

\section{Related Work}

Conventional machine learning approaches 
-longest common subsequence: uses the class of the trajectory with the longest common subsequence as the input trajectory as the prediction
-SVM, logistic regression + bag of words

RNN-based approaches
- TULER: lookup embeddings + LSTM/GRU
- TULVAE: combines Variational Autoencoder with LSTM classifier that is additionally trained to minimize the expected reconstruction error when appending its predictions to the latent embeddings of the AE
- DeepTUL: adds a historical attention module to TULER that generates an additional context vector by embedding historical check-ins present in the trajectory to be classified

Transformer-based approaches
- T3S: uses a transformer that encodes the sequence of visited grid cells which is concatenated with an LSTM embedding of the coordinate sequence
- TULHOR: uses a modified BERT model that is first pre-trained on sequences of check-ins and grid cells in between each check-in and subsequently finetuned for TUL
- MainTUL: makes use of an RNN and a transformer encoder, which receive the input trajectory and a version of the trajectory augmented with historical data of the same user respectively. The encoders also receive the sequence of POI categories. The transformer outputs are distilled into the RNN.



\section{Preliminaries}

\subsection{Trajectory User Linking}
\subsection{Online Learning}

\subsection{Trajectory-User Linking}

\subsection{Online Machine Learning}

\section{Approach}

\section{Experiments}

As data sources, we select the commonly used public trajectory datasets Geolife, Foursquare-NYC and Foursquare-TKY which we pre-process according to \citet{chenMutualDistillationLearning2022a} by splitting each trajectory into sub-trajectories with a maximum length of 24 hours for Foursquare-NYC and TKY and 3 hours for Geolife and select the most active users.
For more information on the selected datasets, refer to Table~\ref{tab:datasets}. 
We implement all models using PyTorch and tune the learning rate, number of layers and model size for each approach on the first 5000 trajectories of Foursquare-TKY. 
For approach-specific hyperparameters, we use the authors suggested default values. 
In terms of data modalities, we use only POIs, coordinates and timestamps. 
For this reason, we omit the model components in MainTUL and TULHOR that require additional data like POI-categories or mobility flows. 
To allow the evaluation of MainTUL and DeepTUL, which require historical data as additional inputs, we maintain a buffer of the most recent 1000 trajectories during each run. 
We use the previously described, unified approach of multi-level lookup-table embeddings that are learned end-to-end. 

\begin{table}[h]
    \centering
\caption{Datasets used for experimental evaluation.}
\label{tab:datasets}
\begin{tabular}{@{}lrrrrr@{}}
\toprule
Dataset        & \# Users & \# Trajectories & \# Check-Ins & \# POIs & Timespan  \\ \midrule
Foursquare-NYC & 800      & 61,218           & 196,435       & 34,383   & 10 months \\
Foursquare-TKY & 800      & 70,007           & 324,564       & 38,212   & 10 months \\
Geolife        & 150      & 25,611           & 1,284,208      & 0       & 64 months \\ \bottomrule
\end{tabular}
\end{table}




\section{Conclusion}



\bibliography{collas2025_conference}
\bibliographystyle{collas2025_conference}

\appendix
\section{Appendix}
You may include other additional sections here.

\end{document}
